# Non Functional characteristics of Distribuited Systems into the Big Data alternative tool in AWS Cloud

**Introduction**
This tutorial is the demostration of non functional properties Distribuid Systems as fault tolerance, performance and cluster concept throught the experiments of an alternative Big Data tool for Athena usable in some use of cases.
**Context for the tutorial**
The following subsections provide a brief overview of how this tutorial fits into the broader context of Big Data as Distribuid Systems with their main characteristics and how with the steps to build and experimental tool it achieve to demostrate the non functional properties.
**Tutorial objectives**
This tutorial teach you how to:
Use services and tools of AWS for Big Data on command line and manually.
Prepare an environment of benchmark Big Data with TPC-DS with Cloud Architecture.
Set and launch a cluster of Elastic Map Reduce with specific with Spark.  
Demostrate the fault tolerance characterstic of distribuited systems.
Demostrate the performance property.
Demostrate the cluster concept.
**Intended audience**
This tutorial is intended for students of grade or postgraduate in Computer Sciences or relative, and who are interested in gaining expertise with charactersitcs of distribuited systems and some specific knowledge of big data analysis on AWS.
Prerequisites
Students should already have dominated the theory od Distribuited Systems and basic knowledge of Big Data, tools and services of AWS.
# Sections
This tutorial has the following parts:
1. [Process to setup of TPC-DS Benchmark Environment in AWS.](#process-to-setup-of-tpcds-benchmark-environment-in-aws)
2. [Setup and run EMR Cluster with access to the TPC-DS Big Data repository throught command line.](#)
3. [Demostration of Fault Tolerance.](#)
4. [Demostration of Performance.](#)
5. [Demostration of Cluster Concept.](#)
## Process to setup of TPC-DS Benchmark Environment in AWS
1\. From (link AWS Redshift) TPC-DS 3TB.
2\. We have to modify the scripts and next we open Athena to run the scripts to create data.
3\. This scripts makes reference to a s3 files.
## Setup and run EMR Cluster with access to the TPC-DS Big Data repository throught command line
## Demostration of Fault Tolerance.
With this we have created our environment witch we can connect from every eam cluster started through the property glue connection. The following Lab shows how perform the fault tolerance in a cluster. We will start a cluster of spark for execute one heavy query and we will do down one server for show that this affects but not in all the process.\ 
## EMR Spark Cluster.
7. We wil use the  two ways for : manual for down te server and scripts  



  